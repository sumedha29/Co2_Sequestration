{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataDrivenLSTM_water.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzA9xUW_d7Cq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_dir = '/content/drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSKlzmyjd8K0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2akVgaM10OQr"
      },
      "source": [
        "tf.compat.v1.disable_v2_behavior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hSpZScmd9gn"
      },
      "source": [
        "all_pressures=[]\n",
        "all_saturations=[]\n",
        "all_permeabilities=[]\n",
        "all_porosities = []\n",
        "all_surf_inj_rate_series = []\n",
        "all_surf_prod_rate_series  = []\n",
        "Ks = []\n",
        "Rs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNdbFaYsd-sh"
      },
      "source": [
        "class GEM_File:\n",
        "\n",
        "    grid_search_keywords = ['*GRID','*CART']\n",
        "    time_search_keywords = ['Time','=','hr']\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "\n",
        "        self.file_name = file_name\n",
        "        self.input_list = self.read_file(self.file_name)\n",
        "        self.current = 0 # pointer to current line number in file\n",
        "        self.nx, self.ny, self.nz = self.get_grid(self.grid_search_keywords)\n",
        "\n",
        "    # read file into list\n",
        "    def read_file(self, file_name):\n",
        "        input_list = []\n",
        "        with open(file_name) as f:\n",
        "            input_list = f.readlines()\n",
        "        return input_list\n",
        "\n",
        "    # read grid dimensions\n",
        "    def get_grid(self, search_strings):\n",
        "        for m,line in enumerate(self.input_list[self.current:]):\n",
        "            if all(elem in line for elem in search_strings):\n",
        "                line_list = line.split()\n",
        "                self.current = self.current + m\n",
        "                return int(line_list[-3]), int(line_list[-2]), int(line_list[-1])\n",
        "        self.current = -1\n",
        "        return -1, -1, -1\n",
        "\n",
        "    # find next time step\n",
        "    def get_time(self, search_strings):\n",
        "        for m,line in enumerate(self.input_list[self.current+1:]):\n",
        "            if all(elem in line for elem in search_strings):\n",
        "                line_list = line.split()\n",
        "                i = line_list.index('=')\n",
        "                # save line number, return time and units\n",
        "                self.current = self.current + m + 1\n",
        "                return float(line_list[i+1]), line_list[i+2]\n",
        "        self.current = -1 # end of file reached\n",
        "        return -1.0, 'days'   \n",
        "\n",
        "    # move file pointer to line containing all search strings in list\n",
        "    def find_it(self, search_strings):\n",
        "        if (self.current < 0):\n",
        "            return\n",
        "        for m,line in enumerate(self.input_list[self.current+1:]):\n",
        "            if all(elem in line for elem in search_strings):\n",
        "                self.current = self.current + m + 1\n",
        "                return\n",
        "        return\n",
        "\n",
        "    # read model layer with constant value into 2D numpy array\n",
        "    def read_constant_layer(self):\n",
        "        line = self.input_list[self.current]\n",
        "        line_list = line.split()\n",
        "        var = np.ones((self.nx,self.ny))*float(line_list[-1])\n",
        "        return var       \n",
        "\n",
        "    # read entire grid with constant value into 3D numpy array\n",
        "    def read_constant_block(self):\n",
        "        line = self.input_list[self.current]\n",
        "        line_list = line.split()\n",
        "        var = np.ones((self.nx,self.ny,self.nz))*float(line_list[-1])\n",
        "        return var\n",
        "\n",
        "    # read a model layer with variable values into 2D numpy array\n",
        "    def read_variable_layer(self):\n",
        "\n",
        "        # converts string to float, fills missing values\n",
        "        def my_float(s):\n",
        "            s = s.strip()\n",
        "            missing = 0.0\n",
        "            return float(s) if s else missing\n",
        "\n",
        "        line = self.input_list[self.current]\n",
        "        var = np.zeros((self.nx,self.ny))\n",
        "        while True:\n",
        "            line_list = line.split()\n",
        "            int_list = list(map(int, line_list[2:]))\n",
        "            for j in range(self.nx):\n",
        "                self.current = self.current + 1\n",
        "                line = self.input_list[self.current]\n",
        "                skip = len(str(self.nx))+4\n",
        "                chunk = int((len(line)-skip)/len(int_list))\n",
        "                line_list = [line[i:i+chunk] for i in range(skip, len(line), chunk)]\n",
        "                float_list = list(map(my_float, line_list[:-1]))\n",
        "                for m,n in enumerate(int_list):\n",
        "                    i = n - 1\n",
        "                    var[i][j] = float_list[m]\n",
        "            if int_list[-1] == self.ny:\n",
        "                break\n",
        "            self.current = self.current + 2\n",
        "            line = self.input_list[self.current]\n",
        "        return var\n",
        "\n",
        "    # read output variable into 2D or 3D numpy array\n",
        "    def read_variable(self):\n",
        "        self.current = self.current + 3\n",
        "        line = self.input_list[self.current]\n",
        "\n",
        "        if self.nz == 1: # 2D\n",
        "            if all(elem in line for elem in ['All','values','are']):\n",
        "                var = self.read_constant_layer()\n",
        "            else:\n",
        "                var = self.read_variable_layer() \n",
        "        else: # 3D\n",
        "            if 'Plane' in line:\n",
        "                var = np.zeros((self.nx,self.ny,self.nz))\n",
        "                for k in range(self.nz):\n",
        "                    if all(elem in line for elem in ['All','values','are']):\n",
        "                        layer = self.read_constant_layer()\n",
        "                    else:\n",
        "                        self.current = self.current + 1                 \n",
        "                        layer = self.read_variable_layer()\n",
        "                    var[:,:,k] = layer\n",
        "                    self.current = self.current + 2\n",
        "                    line = self.input_list[self.current]\n",
        "            else:\n",
        "                 var = self.read_constant_block()\n",
        "        return var\n",
        "\n",
        "    # get output variable at all time steps\n",
        "    def get_variable(self, search_strings):\n",
        "        self.current = 0 # go to beginning of file\n",
        "        variables = {}\n",
        "        while True:\n",
        "            # look for next time step\n",
        "            time, units = self.get_time(self.time_search_keywords)\n",
        "            if (self.current == -1.0): return variables # end of file\n",
        "            # get the selected variable values\n",
        "            self.find_it(search_strings)\n",
        "            var = self.read_variable()\n",
        "            variables.update({time : var})\n",
        "        return variables\n",
        "\n",
        "    # get list of well coordinates\n",
        "    def get_well_coords(self, well_num, location_strings):\n",
        "        self.current = 0 # go to beginning of file\n",
        "       # find well coordinates\n",
        "        well_str = str(well_num)\n",
        "        location_strings.append(well_str)\n",
        "        self.find_it(location_strings)\n",
        "        self.current = self.current + 1\n",
        "        line = self.input_list[self.current]\n",
        "        line_list = line.split()\n",
        "        i = int(line_list[0])\n",
        "        j = int(line_list[1])\n",
        "        k_string = line_list[2]\n",
        "        if ':' in k_string:\n",
        "            k_list = k_string.split(':')\n",
        "            k1 = int(k_list[0])\n",
        "            k2 = int(k_list[1])\n",
        "            coords = [(i, j, k) for k in range(k1,k2+1)]\n",
        "        else:\n",
        "            k = [int(line_list[2])]\n",
        "            coords = [(i, j, k)]\n",
        "        return coords\n",
        "\n",
        "    # get well operating parameters\n",
        "    def get_well_params(self, well_num, search_strings, subsearch_strings):\n",
        "        self.current = 0 # go to beginning of file\n",
        "        well_str = str(well_num)\n",
        "        search_strings.append(well_str)\n",
        "        self.find_it(search_strings)\n",
        "        self.find_it(subsearch_strings)\n",
        "        line = self.input_list[self.current]\n",
        "        line_list = line.split()\n",
        "        return float(line_list[-1])\n",
        "\n",
        "    # get well surface rate at a particular time\n",
        "    def get_well_surface_rate(self, well_num, search_strings, subsearch_strings):\n",
        "            # look for well rate\n",
        "            self.find_it(search_strings)\n",
        "            self.find_it(subsearch_strings)\n",
        "            line = self.input_list[self.current]\n",
        "            line_list = line.split()[len(subsearch_strings):]\n",
        "            return float(line_list[well_num*2-1])        \n",
        "\n",
        "    # get well surface rates as a dictionary of rate vs time\n",
        "    def get_well_surface_rates(self, well_num, search_strings, subsearch_strings):\n",
        "        self.current = 0\n",
        "        values = {}\n",
        "        # look for time zero\n",
        "        time, units = self.get_time(self.time_search_keywords)\n",
        "        # no injection at time zero\n",
        "        values.update({time : 0.0})\n",
        "        while True:\n",
        "            # look for next time step\n",
        "            time, units = self.get_time(self.time_search_keywords)\n",
        "            if (self.current == -1.0): return values # end of file\n",
        "            rate = self.get_well_surface_rate(well_num, search_strings, subsearch_strings)\n",
        "            values.update({time : rate})\n",
        "        return values\n",
        "\n",
        "    # get well surface rates as a dictionary of 2D numpy arrays shaped like the top surface of the model grid\n",
        "    def get_well_surface_maps(self, well_num, location_strings, search_strings, subsearch_strings):\n",
        "        self.current = 0\n",
        "        variables = {}\n",
        "        i,j,k = self.get_well_coords(well_num, location_strings)[0]\n",
        "        rates = self.get_well_surface_rates(well_num, search_strings, subsearch_strings)\n",
        "        for time,rate in rates.items():\n",
        "            var = np.zeros((self.nx,self.ny))\n",
        "            var[i-1][j-1] = rate\n",
        "            variables.update({time : var})\n",
        "        return variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXO7ET2heAlj"
      },
      "source": [
        "files = sorted(glob.glob('/content/drive/My Drive/Colab Notebooks/ToyModel2NewData/*.out')) # 3D Grid with missing values\n",
        "\n",
        "print('All files:', files)\n",
        "\n",
        "for fil in files:\n",
        "    print('Processing file: ', fil)\n",
        "    permeability = int(fil.split('k')[2][0])\n",
        "    injection_rate = int(fil.split('r')[3][0])\n",
        "    Ks.append(int(permeability)-1)\n",
        "    Rs.append(int(injection_rate)-1)\n",
        "    \n",
        "    file = GEM_File(fil)\n",
        "\n",
        "    # get a dictionary of pressures in numpy array vs time\n",
        "    pressures = file.get_variable(['Pressure','(psia)'])\n",
        "    # print('pressures', pressures)\n",
        "\n",
        "    # get a list of all time steps\n",
        "    times = list(pressures.keys())\n",
        "    # print('times', times)\n",
        "\n",
        "    # get a dictionary of saturations in numpy array vs time\n",
        "    saturations = file.get_variable(['Gas','Saturation'])\n",
        "    # print('saturations', saturations)\n",
        "\n",
        "    # get a dictionary of I-direction permeabilities in numpy array vs time\n",
        "    permeabilities = file.get_variable(['I-direction','Permeabilities'])\n",
        "    # print('permeabilities', permeabilities)\n",
        "\n",
        "    # get a dictionary of porosities in numpy array vs time\n",
        "    porosities = file.get_variable(['Current','Porosity'])\n",
        "    # print('porosities', porosities)\n",
        "\n",
        "    # get a dictionary of surface CO2 injection rates vs time for well #1\n",
        "    surf_inj_rate_series = file.get_well_surface_rates(1,['Inst','Surface','Injection','Rates'],['Gas','MSCF/day'])\n",
        "    # print('surf_inj_rate_series', surf_inj_rate_series)\n",
        "    \n",
        "    # # get a dictionary of surface water production rates vs time for well #2\n",
        "    surf_prod_rate_series = file.get_well_surface_rates(2,['Inst','Surface','Production','Rates'],['Water','STB/day'])\n",
        "    # print('surf_prod_rate_series', surf_prod_rate_series)\n",
        "    \n",
        "    if fil=='k1r1-h.out':\n",
        "        surf_prod_rate_series[60] = surf_prod_rate_series[31]\n",
        "        surf_prod_rate_series = collections.OrderedDict(sorted(surf_prod_rate_series.items()))\n",
        "\n",
        "    # get a dictionary of surface CO2 injection rates in 2D numpy array vs time for well #1\n",
        "    surf_inj_rate_maps = file.get_well_surface_maps(1,['*PERF','*GEO'], ['Inst','Surface','Injection','Rates'], ['Gas','MSCF/day'])\n",
        "    # print('surf_inj_rate_maps', surf_inj_rate_maps)\n",
        "\n",
        "    # get a dictionary of surface water production rates in 2D numpy array vs time for well #2\n",
        "    surf_prod_rate_maps = file.get_well_surface_maps(2,['*PERF','*GEO'], ['Inst','Surface','Production','Rates'], ['Water','STB/day'])\n",
        "    # print('surf_prod_rate_maps', surf_prod_rate_maps)\n",
        "\n",
        "    pressures_np = np.array(list(pressures.values()))\n",
        "    all_pressures.append(pressures_np)\n",
        "    \n",
        "    saturations_np = np.array(list(saturations.values()))\n",
        "    all_saturations.append(saturations_np)\n",
        "    \n",
        "    permeabilities_np = np.array(list(permeabilities.values()))\n",
        "    all_permeabilities.append(permeabilities_np)\n",
        "    \n",
        "    porosities_np = np.array(list(porosities.values()))\n",
        "    all_porosities.append(porosities_np)\n",
        "    \n",
        "    surf_inj_rate_series_np = np.array(list(surf_inj_rate_series.values()))\n",
        "    print(surf_inj_rate_series_np.shape)\n",
        "    all_surf_inj_rate_series.append(surf_inj_rate_series_np)\n",
        "    \n",
        "    surf_prod_rate_series_np = np.array(list(surf_prod_rate_series.values()))\n",
        "    all_surf_prod_rate_series.append(surf_prod_rate_series_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5IVAZL_eDzt"
      },
      "source": [
        "Ks = np.reshape(Ks, (27,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "887E8dPieE7X"
      },
      "source": [
        "Rs = np.reshape(Rs, (27,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZUijSWUeHfM"
      },
      "source": [
        "all_pressures = np.array(all_pressures)\n",
        "print(all_pressures.shape)\n",
        "\n",
        "all_saturations = np.array(all_saturations)\n",
        "print(all_saturations.shape)\n",
        "\n",
        "all_permeabilities = np.array(all_permeabilities)\n",
        "print(all_permeabilities.shape)\n",
        "\n",
        "all_porosities = np.array(all_porosities)\n",
        "print(all_porosities.shape)\n",
        "\n",
        "all_surf_inj_rate_series = np.array(all_surf_inj_rate_series)\n",
        "print(all_surf_inj_rate_series.shape)\n",
        "\n",
        "all_surf_prod_rate_series = np.array(all_surf_prod_rate_series)\n",
        "print(all_surf_prod_rate_series.shape)\n",
        "\n",
        "\n",
        "#normalizing pressures\n",
        "max_ = np.amax(all_pressures)\n",
        "min_ = np.amin(all_pressures)\n",
        "all_pressures = (all_pressures-min_)/(max_-min_)\n",
        "\n",
        "\n",
        "#normalizing saturation\n",
        "max_ = np.amax(all_saturations)\n",
        "min_ = np.amin(all_saturations)\n",
        "all_saturations = (all_saturations-min_)/(max_-min_)\n",
        "\n",
        "#normalizing permeabilities\n",
        "max_ = np.amax(all_permeabilities)\n",
        "min_ = np.amin(all_permeabilities)\n",
        "all_permeabilities = (all_permeabilities-min_)/(max_-min_)\n",
        "\n",
        "#normalizing porosities\n",
        "max_ = np.amax(all_porosities)\n",
        "min_ = np.amin(all_porosities)\n",
        "all_porosities = (all_porosities-min_)/(max_-min_)\n",
        "\n",
        "#normalizing surf_inj_rate_series\n",
        "max_ = np.amax(all_surf_inj_rate_series)\n",
        "min_ = np.amin(all_surf_inj_rate_series)\n",
        "all_surf_inj_rate_series = (all_surf_inj_rate_series-min_)/(max_-min_)\n",
        "\n",
        "#normalizing \n",
        "max_ = np.amax(all_surf_prod_rate_series)\n",
        "min_ = np.amin(all_surf_prod_rate_series)\n",
        "all_surf_prod_rate_series = (all_surf_prod_rate_series-min_)/(max_-min_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNEgplHRcW6P"
      },
      "source": [
        "features1 = []\r\n",
        "target3 = []\r\n",
        "\r\n",
        "for i in range(all_pressures.shape[0]):\r\n",
        "    for j in range(all_pressures.shape[1]):\r\n",
        "        for k in range(all_pressures.shape[2]):\r\n",
        "            for l in range(all_pressures.shape[3]):\r\n",
        "                for m in range(all_pressures.shape[4]):\r\n",
        "                    if j == 0 or j == 1 or j == 2:\r\n",
        "                        features1.append([[(k/24),(l/24),(m/2),(j/71),(all_permeabilities[i][j][k][l][m]),(all_porosities[i][j][k][l][m]),(all_surf_inj_rate_series[i][j])], \r\n",
        "                                     [(k/24),(l/24),(m/2),(j/71),(all_permeabilities[i][j][k][l][m]),(all_porosities[i][j][k][l][m]),(all_surf_inj_rate_series[i][j])],\r\n",
        "                                     [(k/24),(l/24),(m/2),(j/71),(all_permeabilities[i][j][k][l][m]),(all_porosities[i][j][k][l][m]),(all_surf_inj_rate_series[i][j])],\r\n",
        "                                     [(k/24),(l/24),(m/2),(j/71),(all_permeabilities[i][j][k][l][m]),(all_porosities[i][j][k][l][m]),(all_surf_inj_rate_series[i][j])]])\r\n",
        "                        target3.append(all_surf_prod_rate_series[i][j])\r\n",
        "                  \r\n",
        "                    features1.append([[(k/24),(l/24),(m/2),(j-3/71),(all_permeabilities[i][j-3][k][l][m]),(all_porosities[i][j-3][k][l][m]),(all_surf_inj_rate_series[i][j-3])], \r\n",
        "                                     [(k/24),(l/24),(m/2),(j-2/71),(all_permeabilities[i][j-2][k][l][m]),(all_porosities[i][j-2][k][l][m]),(all_surf_inj_rate_series[i][j-2])],\r\n",
        "                                     [(k/24),(l/24),(m/2),(j-1/71),(all_permeabilities[i][j-1][k][l][m]),(all_porosities[i][j-1][k][l][m]),(all_surf_inj_rate_series[i][j-1])],\r\n",
        "                                     [(k/24),(l/24),(m/2),(j/71),(all_permeabilities[i][j][k][l][m]),(all_porosities[i][j][k][l][m]),(all_surf_inj_rate_series[i][j])]])\r\n",
        "                    target3.append(all_surf_prod_rate_series[i][j])\r\n",
        "\r\n",
        "features1 = np.array(features1)\r\n",
        "target3 = np.array(target3)\r\n",
        "target3 = np.expand_dims(target3, axis=1)\r\n",
        "print(features1.shape)\r\n",
        "print(target3.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZeluMv5cdOa"
      },
      "source": [
        "features1_tr1 = features1[:2*72*25*25*3]\r\n",
        "features1_te1 = features1[2*72*25*25*3:4*72*25*25*3]\r\n",
        "features1_tr2 = features1[4*72*25*25*3:11*72*25*25*3]\r\n",
        "features1_te2 = features1[11*72*25*25*3:12*72*25*25*3]\r\n",
        "features1_tr3 = features1[12*72*25*25*3:]\r\n",
        "\r\n",
        "features1_tr = np.concatenate((features1_tr1,features1_tr2,features1_tr3))\r\n",
        "features1_te = np.concatenate((features1_te1,features1_te2))\r\n",
        "\r\n",
        "target3_tr1 = target3[:2*72*25*25*3]\r\n",
        "target3_te1 = target3[2*72*25*25*3:4*72*25*25*3]\r\n",
        "target3_tr2 = target3[4*72*25*25*3:11*72*25*25*3]\r\n",
        "target3_te2 = target3[11*72*25*25*3:12*72*25*25*3]\r\n",
        "target3_tr3 = target3[12*72*25*25*3:]\r\n",
        "\r\n",
        "target3_tr = np.concatenate((target3_tr1,target3_tr2,target3_tr3))\r\n",
        "target3_te = np.concatenate((target3_te1,target3_te2))\r\n",
        "\r\n",
        "from sklearn.utils import shuffle\r\n",
        "features1_tr,target3_tr = shuffle(features1_tr,target3_tr, random_state=0)\r\n",
        "\r\n",
        "print(features1_tr.shape)\r\n",
        "print(target3_tr.shape)\r\n",
        "print(features1_te.shape)\r\n",
        "print(target3_te.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSqLNnsMgIH4"
      },
      "source": [
        "batch_size = 250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnkKs-WgUBi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import collections\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzW5VIeDPgWG"
      },
      "source": [
        "input_2 = layers.Input(shape=(4, 7), name='second_input')\n",
        "lstm_1 = LSTM(units=128, activation='relu', return_sequences=True, unroll=True)(input_2) \n",
        "lstm_2 = LSTM(units=64, activation='relu', unroll=True)(lstm_1) \n",
        "hidden_1 = Dense(32, activation='relu')(lstm_2)\n",
        "hidden_2 = Dense(16, activation='relu')(hidden_1)\n",
        "hidden_3 = Dense(8, activation='relu')(hidden_2) \n",
        "out3 = Dense(1, activation='relu', name='water')(hidden_3)\n",
        "print('out3 done ~')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbhyZNBgXg6u"
      },
      "source": [
        "checkpoint_filepath = '/content/drive/My Drive/Colab Notebooks/models_lstm/water_{val_loss:.8f}.h5'\n",
        "callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g2iIbUxQ18q"
      },
      "source": [
        "model = keras.Model(inputs=input_2,outputs=out3)\n",
        "model.compile(loss='mse', optimizer=keras.optimizers.Adam(1e-4), metrics=['mae'])\n",
        "print(model.summary())\n",
        "history = model.fit(features1_tr, target3_tr, epochs=100, batch_size=250,validation_data=(features1_te,target3_te),shuffle=True,callbacks=[callback], verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
